{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The two most popular implementations of Boosting Trees are [XGBoost](https://en.wikipedia.org/wiki/XGBoost) and [LightGBM](https://en.wikipedia.org/wiki/LightGBM). In this notebook we use XGBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Analyzing the performance of the resulting classifier.\n",
    "In this notebook we look into the result of running XGBoost on the Whale Classification problem. We are interested in two things:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Accuracy:**   A classifier is accurate if it makes few errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Stability / Confidence**  A classifier is stable if replacing the training set causes only small change in the predictions. An abstaining classifier outputs \"IDK\" when on examples where the prediction is unstable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T21:39:00.558778Z",
     "start_time": "2020-05-16T21:38:59.478397Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'XGBHelper'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mXGBHelper\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxgbh\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m xgbh2\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogger\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logger\n\u001b[1;32m     11\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mload_ext\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mautoreload\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Class15/lib/xgbh2.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m roc_curve\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mXGBHelper\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxgbh\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_log\u001b[39m(Log):\n\u001b[1;32m      9\u001b[0m     figure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m5\u001b[39m))\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'XGBHelper'"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import lib.XGBHelper as xgbh\n",
    "from lib import xgbh2\n",
    "\n",
    "from lib.logger import logger\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "f'Version of xgb={xgb.__version__}, should be at least 1.5.1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The data files were preprocessed on PySpark (10 nodes) cluster. The code for the same can be found [here](Data_Processing_Whales.ipynb). The preprocessed is a numpy array with `4175` rows (for the 10mb file) with following columns (zero-indexed):\n",
    "* Col 0-9: projections on first 10 eigen vectors\n",
    "* Col 10: rmse\n",
    "* Col 11: peak2peak\n",
    "* Col 12: label (`0 if row.species==u'Gervais' else 1`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Partitioning the data\n",
    "\n",
    "The data is shuffled and divided as follow:\n",
    "\n",
    "* **85%** of the data is used to perform bootstrap analysis of training variability. This data is partitioned into training and validation many times to produce many validation-set predictions for each example\n",
    "   * **70% Training:**   Used to train the model\n",
    "   * **15% Validation:** Used to evaluate the model\n",
    "   \n",
    "\n",
    "\n",
    "* **15%** of the data is held-out for final testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T21:39:00.597205Z",
     "start_time": "2020-05-16T21:39:00.563043Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self,filename):\n",
    "        data  = np.load(filename)\n",
    "        print(f'data file={filename}, shape={data.shape}')\n",
    "\n",
    "        X = data[:, :-1]\n",
    "        y = np.array(data[:, -1], dtype=int)\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30)\n",
    "        X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5)\n",
    "\n",
    "        dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "        dval = xgb.DMatrix(X_val, y_val)\n",
    "        dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "        self.S={'data':data,\n",
    "           'X':X,'y':y,\n",
    "           'X_train':X_train, 'y_train':y_train, \n",
    "           'X_test':X_test, 'y_test':y_test, \n",
    "           'X_val':X_val,   'y_val':y_val,\n",
    "           'dtrain':dtrain, 'dval':dval, 'dtest':dtest      \n",
    "          }\n",
    "    def get(self,L):\n",
    "        answer=[]\n",
    "        for l in L:\n",
    "            assert l in self.S, f'DataLoader.get: no item named {l} in {self.S.keys()}'\n",
    "            answer.append(self.S[l])\n",
    "        return answer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source='/Users/yoavfreund/datasets/Whales/'\n",
    "data_files=[data_source+\"processed_data_15mb.np\",data_source+\"processed_data_150mb.np\"]\n",
    "D=DataLoader(data_files[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Setting Parameters for XG Boost\n",
    "* Maximum Depth of the Tree = 3 _(maximum depth of each decision trees)_\n",
    "* Step size shrinkage used in update to prevents overfitting = 0.3 _(how to weigh trees in subsequent iterations)_\n",
    "* Maximum Number of Iterations = 1000 _(total number trees for boosting)_\n",
    "* Early Stop if score on Validation does not improve for 5 iterations\n",
    "\n",
    "[Full description of options](https://xgboost.readthedocs.io/en/latest//parameter.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Evaluation metrics:\n",
    "* Recall:\n",
    "   * Input feature vector: $x$, label:  $y=\\pm 1$\n",
    "   * Final score: $F(x)=\\sum_i \\alpha_i h_i(x)$ \n",
    "   * Margins:$m(x,y) = yF(x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Data size: $n$\n",
    "* **error rate** $\\frac{1}{n}\\sum_{i=1}^n{\\bf 1}\\left(m(x_i,y_i) \\leq 0\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **logitboost potential**: $$\\frac{1}{n}\\sum_{i=1} \\log \\left[1+ e^{-m(x_i,y_i)} \\right]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* Logitboost potential $\\geq$ error rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T21:39:00.639247Z",
     "start_time": "2020-05-16T21:39:00.620681Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "param = {}\n",
    "param['max_depth']= 3   # depth of tree\n",
    "param['eta'] = 0.3      # shrinkage parameter\n",
    "param['verbosity'] = 0  # 0= no logging 3=max logging\n",
    "param['objective'] = 'binary:logistic'\n",
    "param['nthread'] = 7 # Number of threads used\n",
    "param['eval_metric'] = ['error','logloss']\n",
    "\n",
    "def param_D2L(param):\n",
    "    \"\"\"Translate a param dictionary to a param list\"\"\"\n",
    "    plist=param.items()\n",
    "    new_plist=[]\n",
    "    for p in plist:\n",
    "        if type(p[1])!=list:\n",
    "            new_plist.append(p)\n",
    "        else:\n",
    "            for e in p[1]:\n",
    "                new_plist.append((p[0],e))\n",
    "    return new_plist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Visualizing Performance\n",
    "* train and test error\n",
    "* train and test average potential (exponential potential)\n",
    "* ROC\n",
    "* Margins and stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T21:39:00.745216Z",
     "start_time": "2020-05-16T21:39:00.726666Z"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def test_xgboost(filename,depth=4,num_round=100):\n",
    "    D=DataLoader(filename)\n",
    "    dtrain,dval,dtest = D.get(['dtrain','dval','dtest'])\n",
    "    evallist = [(dtrain, 'train'), (dtest, 'eval')]\n",
    "    param['max_depth']= depth   # depth of tree\n",
    "    evals_result={}\n",
    "    bst = xgb.train(param_D2L(param), dtrain, num_round, evallist,\\\n",
    "                    verbose_eval=False, evals_result=evals_result)\n",
    "    plot_log(evals_result)\n",
    "    return bst\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Tree Depth 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "bst=test_xgboost(data_files[0],depth=1,num_round=1000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "test_xgboost(data_files[1],depth=1,num_round=1000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Tree Depth 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "test_xgboost(data_files[0],depth=2,num_round=1000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "test_xgboost(data_files[1],depth=2,num_round=1000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Tree Depth 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "test_xgboost(data_files[0],depth=3,num_round=1000);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "test_xgboost(data_files[1],depth=3,num_round=1000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Tree Depth 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "test_xgboost(data_files[0],depth=4,num_round=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "test_xgboost(data_files[1],depth=4,num_round=1000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Tree Depth 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "test_xgboost(data_files[0],depth=5,num_round=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "test_xgboost(data_files[1],depth=5,num_round=1000);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compute ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bst=test_xgboost(data_files[1],depth=4,num_round=200);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D=DataLoader(filename=data_files[0])\n",
    "y_test,dtest = D.get(['y_test','dtest'])\n",
    "bst_100=test_xgboost(data_files[1],depth=4,num_round=100)\n",
    "y_pred_100 = bst_100.predict(dtest,output_margin=True)\n",
    "bst_1000=test_xgboost(data_files[1],depth=4,num_round=1000)\n",
    "y_pred_1000 = bst_1000.predict(dtest,output_margin=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib import XGBHelper as xgbh\n",
    "xgbh.plot_roc(y_test,[(y_pred_100,'100_iterations'),(y_pred_1000,'1000_iterations')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Stability of the Margins.\n",
    "Margins on the training set are predictive of margins of the test set, which is why margins are a better measure of performance than the training error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* We want to see how variable is the CDF of the scores, as a function of the size of the training set.\n",
    "* We use bootstrap sampling.\n",
    "* We plot the CDF for each class for each of the bootstrap samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import choice\n",
    "\n",
    "def bootstrap_sample(X,y):\n",
    "    assert X.shape[0]==y.shape[0]\n",
    "    l=X.shape[0]\n",
    "\n",
    "    C=choice(array(range(l)),l,replace=True)\n",
    "    Xresamp=X[C]\n",
    "    yresamp=y[C]\n",
    "    return Xresamp,yresamp\n",
    "#bootstrap_sample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T21:39:47.011327Z",
     "start_time": "2020-05-16T21:39:46.930971Z"
    },
    "hide_input": false,
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "def plot_margins(X,y,_train_size,ensemble_size=20,TrainingRounds=[10,200],\\\n",
    "                 labels=['Cuviers','Gervais']):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    models={iters:[] for iters in TrainingRounds}\n",
    "\n",
    "    for i in range(ensemble_size):  #iterate over randomized training of the classifier\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=_train_size,test_size=1-_train_size)\n",
    "        X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5)\n",
    "\n",
    "        dval = xgb.DMatrix(X_val, y_val)\n",
    "        dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "        legends=[]\n",
    "\n",
    "        for num_round in TrainingRounds:  # Number of training iterations\n",
    "            X_train_bootstrap,y_train_bootstrap=bootstrap_sample(X_train,y_train)\n",
    "            dtrain = xgb.DMatrix(X_train_bootstrap, label=y_train_bootstrap)\n",
    "            evallist = [(dtrain, 'train'), (dtest, 'eval')]\n",
    "            bst = xgb.train(param_D2L(param), dtrain, num_round, evallist, verbose_eval=False)\n",
    "            \n",
    "            models[num_round].append(bst)\n",
    "            y_pred = bst.predict(dtest,output_margin=True)\n",
    "            thresholds = sorted(np.unique(np.round(y_pred, 2)))\n",
    "            error_cuv, error_ger = xgbh.get_error_values(y_pred, y_test, thresholds)\n",
    "            legends += [f'{labels[0]}{num_round}', f'{labels[1]}{num_round}']\n",
    "            _style=['y','g'] if num_round==10 else ['b', 'r']\n",
    "            xgbh.get_margin_plot(error_cuv, error_ger, thresholds, legends = legends, style=_style)\n",
    "        \n",
    "        plt.grid(which='major', linestyle='-', linewidth='0.5', color='gray')\n",
    "        plt.grid(which='minor', linestyle=':', linewidth='0.5', color='gray')\n",
    "        thr = thresholds/(np.max(thresholds) - np.min(thresholds))\n",
    "    plt.title('train size=%4.3f, test size=%4.3f'%(X_train.shape[0],X_test.shape[0]))\n",
    "    plt.show()\n",
    "    return models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stability Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D=DataLoader(data_files[0])\n",
    "X,y=D.get(['X','y'])\n",
    "models=plot_margins(X,y,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=plot_margins(X,y,0.9);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T21:39:57.817457Z",
     "start_time": "2020-05-16T21:39:47.015642Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "models=plot_margins(X,y,0.5);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-16T21:40:09.645030Z",
     "start_time": "2020-05-16T21:39:57.824824Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "D=DataLoader(data_files[1])\n",
    "X,y=D.get(['X','y'])\n",
    "models=plot_margins(X,y,0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Things to think about\n",
    "* If you consider the graphs of the error and log loss as a function of the number of boosting iterations, what would you select for tree depth and number of boosting iterations?\n",
    "* If you consider the same question using the margins plots, what would be your conclusions in that case?\n",
    "* Suppose the scores are split into three ranges using two threshold, the left threshold and the right threshold. TO the left of the left threshold you predict `Cuviers`, and to the right of the right threshold you predict `Gervais`. Between the two thresholds you don't predict, i.e. you say \"I don't know\". If you say \"I don't know\" you lose nothing. If you predict and you are right, you get 1 dollar. and if you predict and you are incorrect you lose 4 dollars. How should you choose the two threshold.\n",
    "\n",
    "Think about these questions and we'll discuss them in the next class!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Summary\n",
    "* We saw how PCA+Boosting are used to solve a real-world problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* We saw several ways to quantify and understand the behaviour of boosted trees.\n",
    "   * Train and test error\n",
    "   * Train and test loss\n",
    "   * ROC curves\n",
    "   * Stability of scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data,=D.get(['data'])\n",
    "data.shape\n",
    "\n",
    "generate_samples(data,num_chunks=23)\n",
    "grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
